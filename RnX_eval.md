# RnX_EVAL
## The following are references for evaluating the performance of explainibility methods

<a href="#FESP">[1]</a>  Mesuring the change in accuracy of prediction in model by keeping X% of top most important features obtained by the explain. method. (See section 4.1)












# References
<div class="csl-entry"> <a id="FESP"> [1] </a> Condevaux, Charles, Sebastien Harispe, et Stephane Mussard. « Fair and Eﬃcient Alternatives to Shapley-Based Attribution Methods », s. d., 16.
 </div>
