## Explainability
- the degree to which a human observer can understand the reason behind a decision (or a prediction) made by the model (Hoa et al., International Conference on Software Engineering, 2018)

## Interpretability
- the capacity to provide or bring out the meaning of an abstract concept and understandability as the capacity to make the model understandable by end-users (Vilone et Long, Information Fusion, 2021)

## Explanation
- *An explanation is the collection of features of the interpretable domain, that have contributed for a given example to produce a decision (e.g. classification or regression) (Montavon et al., Digital Signal Processing, 2018)

## Interpretation
- *The mapping of an abstract concept (e.g. a predicted class) into a domain that the human can make sense of (Montavon et al., Digital Signal Processing, 2018)

## important feature 
- class specific feature (Wilming et al. 2022)

## Counterfactual Explanations 
- a class of model interpretation methods that seek to answer: what perturbations to the input are needed for a modelâ€™s prediction to change in a particular way? (Abid et al. 2022)


### Requirements for interpretability
- fidelity (Alvarez-Melis et Jaakkola, 2018)
